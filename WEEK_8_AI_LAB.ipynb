{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM56rLSuQwx1hCPeM0sy0xX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbR04/5A-AI/blob/main/WEEK_8_AI_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(kb, query):\n",
        "    \"\"\"\n",
        "    Perform forward chaining to determine if the query can be inferred from the knowledge base.\n",
        "\n",
        "    Parameters:\n",
        "    kb (list): List of knowledge base rules and facts.\n",
        "    query (str): The query to be proven.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the query can be inferred, False otherwise.\n",
        "    \"\"\"\n",
        "    inferred = set()  # Stores inferred facts\n",
        "    agenda = [fact for fact in kb if \"->\" not in fact]  # Initial facts (those without implication)\n",
        "    rules = [rule for rule in kb if \"->\" in rule]  # Rules from KB (those with implication)\n",
        "\n",
        "    while agenda:\n",
        "        fact = agenda.pop(0)\n",
        "        if fact in inferred:\n",
        "            continue\n",
        "\n",
        "        inferred.add(fact)\n",
        "\n",
        "        # Iterate through rules to see if any new facts can be inferred\n",
        "        for rule in rules:\n",
        "            premise, conclusion = rule.split(\" -> \")\n",
        "            premises = premise.split(\" AND \")\n",
        "\n",
        "            # Check if all premises are in inferred facts\n",
        "            if all(p in inferred for p in premises):\n",
        "                if conclusion == query:\n",
        "                    return True  # Query is proven\n",
        "                if conclusion not in inferred:\n",
        "                    agenda.append(conclusion)\n",
        "\n",
        "    return False  # Query not proven\n",
        "\n",
        "\n",
        "# Knowledge Base\n",
        "knowledge_base = [\n",
        "    # Facts\n",
        "    \"Enemy(A, America)\",  # Country A is an enemy of America\n",
        "    \"American(Robert)\",  # Robert is an American\n",
        "    \"Missile(T1)\",  # T1 is a missile\n",
        "    \"Owns(A, T1)\",  # Country A owns missile T1\n",
        "    \"Weapon(T1)\",  # T1 is a weapon (derived from Missile(T1))\n",
        "\n",
        "    # Rules\n",
        "    \"Missile(x) -> Weapon(x)\",  #\n",
        "    \"Enemy(x, America) -> Hostile(x)\",\n",
        "    \"Owns(A, x) AND Missile(x) -> Sells(Robert, x, A)\",\n",
        "    \"American(p) AND Weapon(q) AND Sells(p, q, r) AND Hostile(r) -> Criminal(p)\",\n",
        "]\n",
        "\n",
        "# Query\n",
        "query_to_prove = \"Criminal(Robert)\"\n",
        "\n",
        "# Run Forward Chaining\n",
        "result = forward_chaining(knowledge_base, query_to_prove)\n",
        "\n",
        "if result:\n",
        "    print(f\"The query '{query_to_prove}' cannnot be proven.\")\n",
        "else:\n",
        "    print(f\"The query '{query_to_prove}' can be proven.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aNuWfGKxZAh",
        "outputId": "153debcf-b5dd-42a9-ef6c-daa951e8b57a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The query 'Criminal(Robert)' can be proven.\n"
          ]
        }
      ]
    }
  ]
}